{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zzmirror/Machine-learning-Basic-projects/blob/main/Regression/Logistic_Regression_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIri-3qiu0FT"
      },
      "source": [
        "# Logistic Regression from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DWdNygsu8a5"
      },
      "source": [
        "\n",
        "\n",
        "#  loading and visualizing \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy_55RX2wdUw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTbR3nVtu7Tm"
      },
      "outputs": [],
      "source": [
        "def load_data(file_path):\n",
        "  data = np.loadtxt(file_path , delimiter=\",\")\n",
        "  x = data[: , :2]\n",
        "  y = data[: , 2]\n",
        "\n",
        "  return x , y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKUwVmpcxVe-"
      },
      "outputs": [],
      "source": [
        "x_train , y_train = load_data('/content/ex2data1.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbAKdnjDzftv"
      },
      "source": [
        "\n",
        "\n",
        "> Checking some elements of data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iUAfWJ6xgcb",
        "outputId": "c7eef4c9-f6d9-4214-83df-d0b9342a6208"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five elements in x_train are : \n",
            " [[34.62365962 78.02469282]\n",
            " [30.28671077 43.89499752]\n",
            " [35.84740877 72.90219803]\n",
            " [60.18259939 86.3085521 ]\n",
            " [79.03273605 75.34437644]] \n",
            " type : <class 'numpy.ndarray'>\n",
            "-------------------------------------\n",
            "First five elements in y_train are : \n",
            " [0. 0. 0. 1. 1.] \n",
            " type : <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(\"First five elements in x_train are : \\n\" , x_train[:5] , \"\\n type :\" , type(x_train))\n",
        "print(\"-------------------------------------\")\n",
        "print(\"First five elements in y_train are : \\n\" , y_train[:5] , \"\\n type :\" , type(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyVsnvsBzpNK"
      },
      "source": [
        "\n",
        "\n",
        "> Checking dimention of our variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT_ZkOiMymy6",
        "outputId": "a5310d2b-ebd0-452f-d3fc-248a99f4f095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train is : (100, 2)\n",
            "Shape of y_train is : (100,)\n",
            "Numberof samples :  100\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of x_train is :\" , x_train.shape)\n",
        "print(\"Shape of y_train is :\" , y_train.shape)\n",
        "print(\"Numberof samples : \" , len(y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erSmTCN53Gaw"
      },
      "source": [
        "\n",
        "\n",
        "> Visualize data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "FOMUoOpw0Sso",
        "outputId": "9bbc639a-d1b7-462c-e3de-b5855dc883a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f73fa8c10>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "positive = y_train == 1\n",
        "negative = y_train == 0\n",
        "\n",
        "plt.plot(x_train[positive , 0] , x_train[positive , 1] , \"k+\" , label = \"y = 1\")\n",
        "plt.plot(x_train[negative , 0] , x_train[negative , 1] , \"yo\" , label = \"y = 0\")\n",
        "plt.xlabel(\"first feature\")\n",
        "plt.ylabel(\"second feature\")\n",
        "plt.legend(loc=\"upper right\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O05o9dCC7lgy"
      },
      "source": [
        "# Building Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBDxlIUo7slY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "> Model : Sigmoid Function\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "    f(x) = g( wa+b)\n",
        "\\end{align}\n",
        "\n",
        "\\begin{align}\n",
        "    g(z) = \\frac{1}{1 +  e^{-z}}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ULrW1BN7lBw"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  \"\"\"\n",
        "  compute the sigmoid of z\n",
        "\n",
        "  Args :\n",
        "    z (ndarray): A scalar, numpy array of any size.\n",
        "\n",
        "  Return :\n",
        "    g (ndarray): sigmoid(z), with the same shape as z\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  g = 1 / (1 + np.exp(-z))\n",
        "\n",
        "  return g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLf11oA4-ViK"
      },
      "source": [
        "\n",
        "\n",
        "> Cost function :\n",
        "\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "J(w , b) = \\frac{1}{m}\\sum_{i=1}^m [ loss (f(x^i) , y^i)]\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "> Loss :\n",
        "\n",
        "\\begin{align}\n",
        "loss(f(x^i) , y^i) = (-y^{i} log(f(x^i)))-(1-y^i)log(1-f(x^i))\n",
        "\\end{align}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyAyswk51g6b"
      },
      "outputs": [],
      "source": [
        "def cost_function(x , y , w , b , lambda_) :\n",
        "  \"\"\"\n",
        "  compute total cost over all samples\n",
        "\n",
        "  Arges :\n",
        "    x : (ndarray Shape (m,n)) data, m examples by n features\n",
        "    y : (array_like Shape (m,)) target value \n",
        "    w : (array_like Shape (n,)) Values of parameters of the model      \n",
        "    b : scalar Values of bias parameter of the model\n",
        "\n",
        "  Return :\n",
        "    total_cost : (scalar)         cost\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  m , n = x.shape\n",
        "  loss = 0\n",
        "\n",
        "  for i in range(m):\n",
        "    z = np.dot(x[i] , w) + b\n",
        "    predict = sigmoid(z)\n",
        "    loss += (-y[i] * np.log(predict)) - ((1 - y[i]) * np.log(1 - predict))\n",
        "\n",
        "  total_cost = loss / m\n",
        "\n",
        "  return total_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aE6oFIwwSod"
      },
      "source": [
        "\n",
        "\n",
        "> Gradient Discent\n",
        "\n",
        "\\begin{align}\n",
        "  w =w-a\\cdot\\frac{\\partial J}{\\partial w} := w -a\\cdot\\frac{1}{n}\\sum_{i=1}^n (h(x)^i - y^i)x^i\n",
        "  \\end{align}\t \n",
        "\\begin{align}\n",
        "  b =b-a\\cdot\\frac{\\partial J}{\\partial b}:= b -a\\cdot\\frac{1}{n}\\sum_{i=1}^n (h(x)^i - y^i)\n",
        "\\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye0El8mtvkJn"
      },
      "outputs": [],
      "source": [
        "def compute_gradient(x , y , w , b , lambda_):\n",
        "  \"\"\"\n",
        "  computes gradient discent for logistic regression\n",
        "\n",
        "  Arges :\n",
        "\n",
        "    x : (ndarray shape (m ,n)) data with m samples and n features\n",
        "    y : (array_like shape (m,)) target values\n",
        "    w : (array_like shape (n,)) weight for features\n",
        "    b : (scaler) Values of bias parameter of the model\n",
        "\n",
        "  Returns : \n",
        "  dj_dw : (array_like shape (n,))\n",
        "  dj_db : (scalar)\n",
        "\n",
        "  \"\"\"\n",
        "  dj_dw = np.zeros(w.shape)\n",
        "  dj_db = 0.0\n",
        "\n",
        "  m , n = x.shape\n",
        "\n",
        "  for i in range(m) : \n",
        "    z = np.dot(x[i] , w) + b\n",
        "    predict = sigmoid(z)\n",
        "    error = predict - y[i]\n",
        "\n",
        "    for j in range(n):\n",
        "      dj_dw[j] += error*x[i , j]\n",
        "\n",
        "    dj_db += error\n",
        "\n",
        "  \n",
        "  dj_dw = dj_dw/m\n",
        "  dj_db = dj_db/m\n",
        "\n",
        "  return dj_dw , dj_db\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d0qOP5S3MtM"
      },
      "source": [
        "# train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u93ebL2B3MFW"
      },
      "outputs": [],
      "source": [
        "def gradient_discent(x , y , w , b , cost_function, gradient_function, alpha, num_iters, lambda_):\n",
        "\n",
        "  w_history = []\n",
        "  cost_history = []\n",
        "\n",
        "  for i in range(num_iters):\n",
        "    dj_dw , dj_db = gradient_function(x , y , w , b , lambda_)\n",
        "    w = w - alpha * dj_dw\n",
        "    b = b - alpha * dj_db\n",
        "\n",
        "    if i<100000:      # prevent resource exhaustion \n",
        "      cost = cost_function(x , y , w , b , lambda_)\n",
        "      cost_history.append(cost)\n",
        "\n",
        "    if i% math.ceil(num_iters/10) == 0 or i == (num_iters-1):\n",
        "      w_history.append(w)\n",
        "      print(f\"Iteration {i:4}: Cost {float(cost_history[-1]):8.2f} \")\n",
        "\n",
        "  return w, b, cost_history, w_history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nESrjRIA22Kj",
        "outputId": "77b346ee-b9ed-4df2-8606-f8af020d89b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration    0: Cost     0.96 \n",
            "Iteration 1000: Cost     0.31 \n",
            "Iteration 2000: Cost     0.30 \n",
            "Iteration 3000: Cost     0.30 \n",
            "Iteration 4000: Cost     0.30 \n",
            "Iteration 5000: Cost     0.30 \n",
            "Iteration 6000: Cost     0.30 \n",
            "Iteration 7000: Cost     0.30 \n",
            "Iteration 8000: Cost     0.30 \n",
            "Iteration 9000: Cost     0.30 \n",
            "Iteration 9999: Cost     0.30 \n"
          ]
        }
      ],
      "source": [
        "np.random.seed(1)\n",
        "intial_w = 0.01 * (np.random.rand(2).reshape(-1,1) - 0.5)\n",
        "initial_b = -8\n",
        "\n",
        "\n",
        "# Some gradient descent settings\n",
        "iterations = 10000\n",
        "alpha = 0.001\n",
        "\n",
        "w,b, J_history,_ = gradient_discent(x_train ,y_train, intial_w, initial_b, cost_function, compute_gradient, alpha, iterations, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Prediction :\n",
        "\n",
        "if\n",
        "\\begin{align}\n",
        " f(x^i) > 0.5 , predict y^i = 1\n",
        "\\end{align}\n",
        "\n",
        "if \n",
        "\n",
        "\\begin{align}\n",
        " f(x^i) < 0.5 , predict y^i = 0\n",
        "\\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "lpHkEryleCx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_JoodB_9YtN"
      },
      "outputs": [],
      "source": [
        "def predict(x , w , b ,treshold ):\n",
        "  \"\"\"\n",
        "    Predict whether the label is 0 or 1 using learned logistic\n",
        "    regression parameters w\n",
        "    \n",
        "    Args:\n",
        "    X : (ndarray Shape (m, n))\n",
        "    w : (array_like Shape (n,))      Parameters of the model\n",
        "    b : (scalar, float)              Parameter of the model\n",
        "    treshold : a number that define our treshhold\n",
        "\n",
        "    Returns:\n",
        "    p: (ndarray (m,1))\n",
        "        The predictions for X using a threshold at 0.5\n",
        "  \"\"\"\n",
        "\n",
        "  m , n = x.shape\n",
        "  p = np.zeros(m)\n",
        "\n",
        "  for i in range(m):\n",
        "\n",
        "    z = np.dot(x[i] , w) + b\n",
        "    prediction = sigmoid(z)\n",
        "\n",
        "    if prediction > treshold :\n",
        "      p[i] = 1\n",
        "    else :\n",
        "      p[i] = 0\n",
        "    \n",
        "  return p\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> accuracy :\n",
        "\n"
      ],
      "metadata": {
        "id": "soz4DVlhhKIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = predict(x_train , w , b , 0.5  )\n",
        "print(\"Train accuracy: %f\"%(np.mean(prediction == y_train)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCfHg64yg5W3",
        "outputId": "044ea63a-ed19-46c0-bc42-d6fbac5c573c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 92.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "When we have a lot of features , our model mostly will over fit .\n",
        "To avoid a complex model and overfiting we will omit some features affect will regularization .\n",
        "\n",
        "\n",
        "\n",
        "> Cost funcation for regularized logistic regression \n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "J(w , b) = \\frac{1}{m}\\sum_{i=1}^m [ -y^{i} log(f(x^i))-(1-y^i)log(1-f(x^i))] + \\frac {λ}{2m} \\sum_{j=0}^{n-1}w_j^2\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gPJgyIc3jI6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regularized_cost(x , y , w , b , lambda_ = 1) :\n",
        "  cost = cost_function(x , y , w , b , lambda_)\n",
        "\n",
        "  m , n = x.shape\n",
        "  reg_cost = 0.\n",
        "\n",
        "  for i in range(n) :\n",
        "    reg_cost += w[i] ** 2\n",
        "  \n",
        "  total_cost = cost + (lambda_  / (2 * m)) * reg_cost\n",
        "  return total_cost\n"
      ],
      "metadata": {
        "id": "vkozmzsmhvMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Gradient Discent with Regularization \n",
        "\n",
        "\\begin{align}\n",
        "  w =w-a\\cdot\\frac{\\partial J}{\\partial w} := w -a\\cdot\\frac{1}{n}\\sum_{i=1}^n (h(x)^i - y^i)x^i + \\frac{\\lambda * w}{m}\n",
        "  \\end{align}\t \n",
        "\\begin{align}\n",
        "  b =b-a\\cdot\\frac{\\partial J}{\\partial b}:= b -a\\cdot\\frac{1}{n}\\sum_{i=1}^n (h(x)^i - y^i)\n",
        "\\end{align}\n",
        "\n"
      ],
      "metadata": {
        "id": "lqMZoTZTtRuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_reg(X, y, w, b, lambda_ = 1): \n",
        "    \"\"\"\n",
        "    Computes the gradient for linear regression \n",
        " \n",
        "    Args:\n",
        "      X : (ndarray Shape (m,n))   variable such as house size \n",
        "      y : (ndarray Shape (m,))    actual value \n",
        "      w : (ndarray Shape (n,))    values of parameters of the model      \n",
        "      b : (scalar)                value of parameter of the model  \n",
        "      lambda_ : (scalar,float)    regularization constant\n",
        "    Returns\n",
        "      dj_db: (scalar)             The gradient of the cost w.r.t. the parameter b. \n",
        "      dj_dw: (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w. \n",
        "\n",
        "    \"\"\"\n",
        "    m, n = X.shape\n",
        "    \n",
        "    dj_db, dj_dw = compute_gradient(X, y, w, b , lambda_)\n",
        "\n",
        "    ### START CODE HERE ###   \n",
        "    \n",
        "    for j in range(n):\n",
        "        dj_dw[j] += (lambda_ * w[j])/m\n",
        "        \n",
        "    \n",
        "        \n",
        "    ### END CODE HERE ###         \n",
        "        \n",
        "    return dj_db, dj_dw"
      ],
      "metadata": {
        "id": "NISoT44-s3IW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNveRJSSeAYfl063ZPPspZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}